{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/bcasares/cs231n_project')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from download_images import loadData\n",
    "from preprocess_data import extractName, getDataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from http://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
    "# and http://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "# define a training image loader that specifies transforms on images. See documentation for more details.\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(64),  # resize the image to 64x64 (remove if images are already 64x64)\n",
    "    transforms.RandomVerticalFlip(),  # randomly flip image vertically\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "# loader for evaluation, no horizontal flip\n",
    "eval_transformer = transforms.Compose([\n",
    "    transforms.Resize(64),  # resize the image to 64x64 (remove if images are already 64x64)\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "\n",
    "class HOUSEDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A standard PyTorch definition of Dataset which defines the functions __len__ and __getitem__.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, transform, train):\n",
    "        \"\"\"\n",
    "        Store the filenames of the jpgs to use. Specifies transforms to apply on images.\n",
    "\n",
    "        Args:\n",
    "            data_dir: (string) directory containing the dataset\n",
    "            transform: (torchvision.transforms) transformation to apply on image\n",
    "        \"\"\"\n",
    "        self.data = getDataLabels()\n",
    "        self.filenames = os.listdir(data_dir)\n",
    "        self.filenames = [os.path.join(data_dir, f) for f in self.filenames if f.endswith('.jpg')]\n",
    "\n",
    "        # self.labels = [int(os.path.split(filename)[-1][0]) for filename in self.filenames]\n",
    "        self.labels = self.getImagesLabel()\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def getImagesLabel(self, id_=\"rowID\", y_id=\"class_label\"):\n",
    "        ids = list(map(extractName, self.filenames))\n",
    "        label = self.data[self.data[id_].isin(ids)][y_id].tolist()\n",
    "        return label\n",
    "\n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetch index idx image and labels from dataset. Perform transforms on image.\n",
    "\n",
    "        Args:\n",
    "            idx: (int) index in [0, 1, ..., size_of_dataset-1]\n",
    "\n",
    "        Returns:\n",
    "            image: (Tensor) transformed image\n",
    "            label: (int) corresponding label of image\n",
    "        \"\"\"\n",
    "        image = Image.open(self.filenames[idx])  # PIL image\n",
    "        image = self.transform(image)\n",
    "        return image, self.labels[idx]\n",
    "\n",
    "\n",
    "def fetch_dataloader(types, data_dir, params):\n",
    "    \"\"\"\n",
    "    Fetches the DataLoader object for each type in types from data_dir.\n",
    "\n",
    "    Args:\n",
    "        types: (list) has one or more of 'train', 'val', 'test' depending on which data is required\n",
    "        data_dir: (string) directory containing the dataset\n",
    "        params: (Params) hyperparameters\n",
    "\n",
    "    Returns:\n",
    "        data: (dict) contains the DataLoader object for each type in types\n",
    "    \"\"\"\n",
    "    dataloaders = {}\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if split in types:\n",
    "            path = os.path.join(data_dir, \"{}\".format(split))\n",
    "\n",
    "            # use the train_transformer if training data, else use eval_transformer without random flip\n",
    "            if split == 'train':\n",
    "                dl = DataLoader(HOUSEDataset(path, train_transformer, train=True), batch_size=params.batch_size, shuffle=True,\n",
    "                                        num_workers=params.num_workers,\n",
    "                                        pin_memory=params.cuda)\n",
    "            if split == \"val\":\n",
    "                dl = DataLoader(HOUSEDataset(path, eval_transformer, train=False), batch_size=params.batch_size, shuffle=False,\n",
    "                                num_workers=params.num_workers,\n",
    "                                pin_memory=params.cuda)\n",
    "            else:\n",
    "                dl = DataLoader(HOUSEDataset(path, eval_transformer, train=False), batch_size=params.batch_size, shuffle=False,\n",
    "                                num_workers=params.num_workers,\n",
    "                                pin_memory=params.cuda)\n",
    "\n",
    "            dataloaders[split] = dl\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join(\"experiments/base_model\", 'params.json')\n",
    "params = utils.Params(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params():\n",
    "    \"\"\"Class that loads hyperparameters from a json file.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    params = Params(json_path)\n",
    "    print(params.learning_rate)\n",
    "    params.learning_rate = 0.5  # change the value of learning_rate in params\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, json_path):\n",
    "        with open(json_path) as f:\n",
    "            params = json.load(f)\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    def save(self, json_path):\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n",
    "            \n",
    "    def update(self, json_path):\n",
    "        \"\"\"Loads parameters from json file\"\"\"\n",
    "        with open(json_path) as f:\n",
    "            params = json.load(f)\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    @property\n",
    "    def dict(self):\n",
    "        \"\"\"Gives dict-like access to Params instance by `params.dict['learning_rate']\"\"\"\n",
    "        return self.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(json_path)\n",
    "params.cuda = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:81: DtypeWarning: Columns (11,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:89: DtypeWarning: Columns (11,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:85: DtypeWarning: Columns (11,37) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "loader_train = fetch_dataloader(\"train\", \"data/HOUSES_SPLIT_64_64\", params)[\"train\"]\n",
    "loader_val = fetch_dataloader(\"val\", \"data/HOUSES_SPLIT_64_64\", params)[\"val\"]\n",
    "loader_test = fetch_dataloader(\"val\", \"data/HOUSES_SPLIT_64_64\", params)[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
    "        # architecture defined above.                                          #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        self.conv_w1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, padding=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w1.weight)\n",
    "        self.conv_w2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w2.weight)\n",
    "        self.fc = nn.Linear(channel_2*64*64, num_classes, bias=True)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #       \n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
    "        # should use the layers you defined in __init__ and specify the        #\n",
    "        # connectivity of those layers in forward()                            #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****     \n",
    "        out = x\n",
    "        out = self.conv_w1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv_w2(out)\n",
    "        out = F.relu(out)\n",
    "        out = flatten(out)\n",
    "        out = self.fc(out)\n",
    "        scores = out\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                             END OF YOUR CODE                         #\n",
    "        ########################################################################\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    num_correct = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "            scores = model(x)\n",
    "            _, preds = scores.max(1)\n",
    "            num_correct += (preds == y).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        acc = float(num_correct) / num_samples\n",
    "        print('Got %d / %d correct (%.2f)' % (num_correct, num_samples, 100 * acc))\n",
    "        return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.long)\n",
    "\n",
    "            scores = model(x)\n",
    "            loss = F.cross_entropy(scores, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()\n",
    "                \n",
    "    return losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# learning_rate = 3e-3\n",
    "# channel_1 = 32\n",
    "# channel_2 = 16\n",
    "\n",
    "# model = None\n",
    "# optimizer = None\n",
    "# ################################################################################\n",
    "# # TODO: Instantiate your ThreeLayerConvNet model and a corresponding optimizer #\n",
    "# ################################################################################\n",
    "# # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# model = ThreeLayerConvNet(3, channel_1, channel_2, 6)\n",
    "# optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "# # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "# ################################################################################\n",
    "# #                                 END OF YOUR CODE                             \n",
    "# ################################################################################\n",
    "\n",
    "# losses = train_part34(model, optimizer, epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 2.1289\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 100, loss = 1.6506\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.2606\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.6595\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 0.8870\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 3.0871\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 1.9594\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.2725\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.6559\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 0.8901\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 3.0692\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 1.9664\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.2722\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.6540\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 0.8909\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 3.0651\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 1.9673\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.2717\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.6532\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 0.8912\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 3.0634\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 1.9675\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.2714\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.6528\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 0.8914\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 3.0625\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.5113\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 0.9257\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.6821\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.0767\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.7008\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 1.2727\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.1558\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.7286\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1275\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.6589\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 1.3575\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.1735\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.7295\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1315\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.6603\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 1.3768\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.1750\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.7283\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1317\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.6618\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 1.3837\n",
      "Checking accuracy on test set\n",
      "Got 649 / 4905 correct (13.23)\n",
      "\n",
      "Iteration 200, loss = 1.1748\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.7274\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1316\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.6628\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8845\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0129\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8999\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.0754\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.5667\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8769\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0357\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8837\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.0976\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.4981\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8788\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0572\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8775\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1172\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.4505\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8832\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0747\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8752\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1328\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.4179\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8877\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0883\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8746\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1447\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3954\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8315\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0668\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8880\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1348\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3914\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8321\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0682\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8880\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1363\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3884\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8328\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0697\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8882\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1378\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3855\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8335\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0711\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8883\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1393\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3827\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8342\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0726\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8885\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1408\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3800\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8288\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0705\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8898\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1398\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3796\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8289\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0706\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8898\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1399\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3794\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8289\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0708\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8898\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1401\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3791\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8290\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8898\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1402\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3788\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8291\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0710\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8898\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1404\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3786\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8286\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0708\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3785\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8286\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3785\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8286\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3785\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8286\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8286\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 0, loss = 1.3784\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 100, loss = 0.8285\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 200, loss = 1.0709\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 300, loss = 0.8900\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n",
      "Iteration 400, loss = 1.1403\n",
      "Checking accuracy on test set\n",
      "Got 1612 / 4905 correct (32.86)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "learning_rates = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9]\n",
    "# learning_rates = [1e-3, 5e-4] \n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "model = ThreeLayerConvNet(3, channel_1, channel_2, 6)\n",
    "losses_model = []\n",
    "for learning_rate in learning_rates:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = train_part34(model, optimizer, epochs=5)\n",
    "    losses_model.append(losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7faf00185400>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, losses in enumerate(losses_model):\n",
    "    if i == 0: \n",
    "        continue\n",
    "    plt.plot(losses, label = str(i))\n",
    "plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
