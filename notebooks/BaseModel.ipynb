{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('/home/bcasares/cs231n_project')\n",
    "# os.chdir('/Users/bcasares/git_folders/cs231n/cs231n_project/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import sampler\n",
    "\n",
    "import torchvision.datasets as dset\n",
    "import torchvision.transforms as T\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "from PIL import Image\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from download_images import loadData\n",
    "from preprocess_data import extractName, getDataLabels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F  # useful stateless functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import utils\n",
    "import json\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(x):\n",
    "    N = x.shape[0] # read in N, C, H, W\n",
    "    return x.view(N, -1)  # \"flatten\" the C * H * W values into a single vector per image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# borrowed from http://pytorch.org/tutorials/advanced/neural_style_tutorial.html\n",
    "# and http://pytorch.org/tutorials/beginner/data_loading_tutorial.html\n",
    "# define a training image loader that specifies transforms on images. See documentation for more details.\n",
    "train_transformer = transforms.Compose([\n",
    "    transforms.Resize(64),  # resize the image to 64x64 (remove if images are already 64x64)\n",
    "    transforms.RandomVerticalFlip(),  # randomly flip image vertically\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "# loader for evaluation, no horizontal flip\n",
    "eval_transformer = transforms.Compose([\n",
    "    transforms.Resize(64),  # resize the image to 64x64 (remove if images are already 64x64)\n",
    "    transforms.ToTensor()])  # transform it into a torch tensor\n",
    "\n",
    "\n",
    "class HOUSEDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A standard PyTorch definition of Dataset which defines the functions __len__ and __getitem__.\n",
    "    \"\"\"\n",
    "    def __init__(self, data_dir, transform, train):\n",
    "        \"\"\"\n",
    "        Store the filenames of the jpgs to use. Specifies transforms to apply on images.\n",
    "\n",
    "        Args:\n",
    "            data_dir: (string) directory containing the dataset\n",
    "            transform: (torchvision.transforms) transformation to apply on image\n",
    "        \"\"\"\n",
    "        self.data = getDataLabels()\n",
    "        self.filenames = os.listdir(data_dir)\n",
    "        self.filenames = [os.path.join(data_dir, f) for f in self.filenames if f.endswith('.jpg')]\n",
    "\n",
    "        # self.labels = [int(os.path.split(filename)[-1][0]) for filename in self.filenames]\n",
    "        self.labels = self.getImagesLabel(y_id=\"log_total_value\")\n",
    "#         print(self.labels)\n",
    "        self.transform = transform\n",
    "        self.train = train\n",
    "\n",
    "    def getImagesLabel(self, id_=\"rowID\", y_id=\"class_label\"):\n",
    "        ids = list(map(extractName, self.filenames))\n",
    "        label = self.data[self.data[id_].isin(ids)][y_id].tolist()\n",
    "        return label\n",
    "\n",
    "    def __len__(self):\n",
    "        # return size of dataset\n",
    "        return len(self.filenames)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Fetch index idx image and labels from dataset. Perform transforms on image.\n",
    "\n",
    "        Args:\n",
    "            idx: (int) index in [0, 1, ..., size_of_dataset-1]\n",
    "\n",
    "        Returns:\n",
    "            image: (Tensor) transformed image\n",
    "            label: (int) corresponding label of image\n",
    "        \"\"\"\n",
    "        image = Image.open(self.filenames[idx])  # PIL image\n",
    "        image = self.transform(image)\n",
    "        label = self.labels[idx]\n",
    "        return image, label\n",
    "\n",
    "\n",
    "def fetch_dataloader(types, data_dir, params):\n",
    "    \"\"\"\n",
    "    Fetches the DataLoader object for each type in types from data_dir.\n",
    "\n",
    "    Args:\n",
    "        types: (list) has one or more of 'train', 'val', 'test' depending on which data is required\n",
    "        data_dir: (string) directory containing the dataset\n",
    "        params: (Params) hyperparameters\n",
    "\n",
    "    Returns:\n",
    "        data: (dict) contains the DataLoader object for each type in types\n",
    "    \"\"\"\n",
    "    dataloaders = {}\n",
    "\n",
    "    for split in ['train', 'val', 'test']:\n",
    "        if split in types:\n",
    "            path = os.path.join(data_dir, \"{}\".format(split))\n",
    "\n",
    "            # use the train_transformer if training data, else use eval_transformer without random flip\n",
    "            if split == 'train':\n",
    "                dl = DataLoader(HOUSEDataset(path, train_transformer, train=True), batch_size=params.batch_size, shuffle=True,\n",
    "                                        num_workers=params.num_workers,\n",
    "                                        pin_memory=params.cuda)\n",
    "            if split == \"val\":\n",
    "                dl = DataLoader(HOUSEDataset(path, eval_transformer, train=False), batch_size=params.batch_size, shuffle=False,\n",
    "                                num_workers=params.num_workers,\n",
    "                                pin_memory=params.cuda)\n",
    "            else:\n",
    "                dl = DataLoader(HOUSEDataset(path, eval_transformer, train=False), batch_size=params.batch_size, shuffle=False,\n",
    "                                num_workers=params.num_workers,\n",
    "                                pin_memory=params.cuda)\n",
    "\n",
    "            dataloaders[split] = dl\n",
    "\n",
    "    return dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_path = os.path.join(\"experiments/base_model\", 'params.json')\n",
    "params = utils.Params(json_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Params():\n",
    "    \"\"\"Class that loads hyperparameters from a json file.\n",
    "\n",
    "    Example:\n",
    "    ```\n",
    "    params = Params(json_path)\n",
    "    print(params.learning_rate)\n",
    "    params.learning_rate = 0.5  # change the value of learning_rate in params\n",
    "    ```\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, json_path):\n",
    "        with open(json_path) as f:\n",
    "            params = json.load(f)\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    def save(self, json_path):\n",
    "        with open(json_path, 'w') as f:\n",
    "            json.dump(self.__dict__, f, indent=4)\n",
    "            \n",
    "    def update(self, json_path):\n",
    "        \"\"\"Loads parameters from json file\"\"\"\n",
    "        with open(json_path) as f:\n",
    "            params = json.load(f)\n",
    "            self.__dict__.update(params)\n",
    "\n",
    "    @property\n",
    "    def dict(self):\n",
    "        \"\"\"Gives dict-like access to Params instance by `params.dict['learning_rate']\"\"\"\n",
    "        return self.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = Params(json_path)\n",
    "params.cuda = torch.cuda.is_available()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:83: DtypeWarning: Columns (11,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:91: DtypeWarning: Columns (11,37) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:87: DtypeWarning: Columns (11,37) have mixed types. Specify dtype option on import or set low_memory=False.\n"
     ]
    }
   ],
   "source": [
    "loader_train = fetch_dataloader(\"train\", \"data/HOUSES_SPLIT_64_64\", params)[\"train\"]\n",
    "loader_val = fetch_dataloader(\"val\", \"data/HOUSES_SPLIT_64_64\", params)[\"val\"]\n",
    "loader_test = fetch_dataloader(\"test\", \"data/HOUSES_SPLIT_64_64\", params)[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using device: cuda\n"
     ]
    }
   ],
   "source": [
    "USE_GPU = True\n",
    "\n",
    "dtype = torch.float32 # we will be using float throughout this tutorial\n",
    "\n",
    "if USE_GPU and torch.cuda.is_available():\n",
    "    device = torch.device('cuda')\n",
    "else:\n",
    "    device = torch.device('cpu')\n",
    "\n",
    "# Constant to control how frequently we print train loss\n",
    "print_every = 100\n",
    "\n",
    "print('using device:', device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThreeLayerConvNet(nn.Module):\n",
    "    def __init__(self, in_channel, channel_1, channel_2, num_classes):\n",
    "        super().__init__()\n",
    "        ########################################################################\n",
    "        # TODO: Set up the layers you need for a three-layer ConvNet with the  #\n",
    "        # architecture defined above.                                          #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        self.conv_w1 = nn.Conv2d(in_channel, channel_1, kernel_size=5, padding=2, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w1.weight)\n",
    "        self.conv_w2 = nn.Conv2d(channel_1, channel_2, kernel_size=3, padding=1, bias=True)\n",
    "        nn.init.kaiming_normal_(self.conv_w2.weight)\n",
    "        self.fc = nn.Linear(channel_2*64*64, num_classes, bias=True)\n",
    "        nn.init.kaiming_normal_(self.fc.weight)\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                          END OF YOUR CODE                            #       \n",
    "        ########################################################################\n",
    "\n",
    "    def forward(self, x):\n",
    "        scores = None\n",
    "        ########################################################################\n",
    "        # TODO: Implement the forward function for a 3-layer ConvNet. you      #\n",
    "        # should use the layers you defined in __init__ and specify the        #\n",
    "        # connectivity of those layers in forward()                            #\n",
    "        ########################################################################\n",
    "        # *****START OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****     \n",
    "        out = x\n",
    "        out = self.conv_w1(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.conv_w2(out)\n",
    "        out = F.relu(out)\n",
    "        out = flatten(out)\n",
    "        out = self.fc(out)\n",
    "        scores = out\n",
    "        # *****END OF YOUR CODE (DO NOT DELETE/MODIFY THIS LINE)*****\n",
    "        ########################################################################\n",
    "        #                             END OF YOUR CODE                         #\n",
    "        ########################################################################\n",
    "        return scores\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_accuracy_part34(loader, model):\n",
    "    if loader.dataset.train:\n",
    "        print('Checking accuracy on validation set')\n",
    "    else:\n",
    "        print('Checking accuracy on test set')   \n",
    "    rmse_sum = 0\n",
    "    num_samples = 0\n",
    "    model.eval()  # set model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        for x, y in loader:\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "            scores = model(x)\n",
    "            preds = scores\n",
    "            rmse_sum += ((preds - y)**2).sum()\n",
    "            num_samples += preds.size(0)\n",
    "        rmse = np.sqrt(float(rmse_sum)) / num_samples\n",
    "        print(\"The RMSE is {}\".format(rmse))\n",
    "        return rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_part34(model, optimizer, epochs=1):\n",
    "    \"\"\"\n",
    "    Train a model on CIFAR-10 using the PyTorch Module API.\n",
    "    \n",
    "    Inputs:\n",
    "    - model: A PyTorch Module giving the model to train.\n",
    "    - optimizer: An Optimizer object we will use to train the model\n",
    "    - epochs: (Optional) A Python integer giving the number of epochs to train for\n",
    "    \n",
    "    Returns: Nothing, but prints model accuracies during training.\n",
    "    \"\"\"\n",
    "    model = model.to(device=device)  # move the model parameters to CPU/GPU\n",
    "    losses = []\n",
    "    for e in range(epochs):\n",
    "        for t, (x, y) in enumerate(loader_train):\n",
    "            model.train()  # put model to training mode\n",
    "            x = x.to(device=device, dtype=dtype)  # move to device, e.g. GPU\n",
    "            y = y.to(device=device, dtype=torch.float)\n",
    "\n",
    "            scores = model(x)\n",
    "#             print(scores)\n",
    "#             print(y)\n",
    "            loss = F.smooth_l1_loss(scores, y)\n",
    "#             loss = F.cross_entropy(scores, y)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            # Zero out all of the gradients for the variables which the optimizer\n",
    "            # will update.\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # This is the backwards pass: compute the gradient of the loss with\n",
    "            # respect to each  parameter of the model.\n",
    "            loss.backward()\n",
    "\n",
    "            # Actually update the parameters of the model using the gradients\n",
    "            # computed by the backwards pass.\n",
    "            optimizer.step()\n",
    "\n",
    "            if t % print_every == 0:\n",
    "                print('Iteration %d, loss = %.4f' % (t, loss.item()))\n",
    "                check_accuracy_part34(loader_val, model)\n",
    "                print()\n",
    "                \n",
    "    return losses "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0, loss = 10.3195\n",
      "Checking accuracy on test set\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Using a target size (torch.Size([32])) that is different to the input size (torch.Size([32, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The RMSE is 1.050743323558643\n",
      "\n",
      "Iteration 100, loss = 0.3552\n",
      "Checking accuracy on test set\n",
      "The RMSE is 0.10117048542932446\n",
      "\n",
      "Iteration 200, loss = 0.2675\n",
      "Checking accuracy on test set\n",
      "The RMSE is 0.10232884599611747\n",
      "\n",
      "Iteration 300, loss = 0.1495\n",
      "Checking accuracy on test set\n",
      "The RMSE is 0.12424755162287161\n",
      "\n",
      "Iteration 400, loss = 0.4486\n",
      "Checking accuracy on test set\n",
      "The RMSE is 0.08368355846135055\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:23: UserWarning: Using a target size (torch.Size([27])) that is different to the input size (torch.Size([27, 1])). This will likely lead to incorrect results due to broadcasting. Please ensure they have the same size.\n"
     ]
    }
   ],
   "source": [
    "# learning_rates = [1e-2, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9]\n",
    "# learning_rates = [1e-2, 2.5e-2, 5e-2, 7.5e-2,  \n",
    "#                   1e-3, 2.5e-3, 5e-3, 7.5e-3,\n",
    "#                   1e-4, 2.5e-4, 5e-4, 7.5e-4,\n",
    "#                   1e-5, 2.5e-5, 5e-5, 7.5e-5,] \n",
    "learning_rates = [1e-3] \n",
    "channel_1 = 32\n",
    "channel_2 = 16\n",
    "\n",
    "model = ThreeLayerConvNet(3, channel_1, channel_2, 1)\n",
    "losses_model = []\n",
    "for learning_rate in learning_rates:\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    losses = train_part34(model, optimizer, epochs=1)\n",
    "    losses_model.append(losses)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "for i, losses in enumerate(losses_model):\n",
    "    plt.figure()\n",
    "    plt.plot(losses, label = str(i))\n",
    "    plt.legend(loc=\"upper right\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
